{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLS 2 WebDataset\n",
    "\n",
    "This notebook and repository will walk you through the process of converting the mls dataset from being on disk, into a streamable dataset easily to split across machines for training.\n",
    "\n",
    "First off, download the dataset from https://openslr.org/94/.\n",
    "\n",
    "Once you have it downloaded and extracted, this notebook can take over from there!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install webdataset pandas torch torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import webdataset as wds\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have what we will be using to import our data. Let's do that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change me to where your data was extracted stored.\n",
    "root_path = os.path.expanduser('/media/jstackhouse/spinner/mls_english')\n",
    "output_dir = os.path.expanduser('~/data/mls_english')\n",
    "\n",
    "# Create the directories if they don't exist for our output.\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def load_split(root: str, split: str) -> pd.DataFrame:\n",
    "    path = os.path.join(root, f\"{split}/transcripts.txt\")\n",
    "    return pd.read_csv(\n",
    "        path, \n",
    "        sep='\\t', \n",
    "        header=None, \n",
    "        names=['path', 'transcript']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will create a tar file per split.\n",
    "splits = [\"dev\", \"train\", \"test\"]\n",
    "for split in splits:\n",
    "    df = load_split(root_path, split)\n",
    "    # The first column is the path to the audio file.\n",
    "    with wds.ShardWriter(f\"{output_dir}/{split}-%04d.tar\") as sink:\n",
    "        for index, row in df.iterrows():\n",
    "            audio_parts = row['path'].split('_')\n",
    "            with open(os.path.join(root_path, split, 'audio', audio_parts[0], audio_parts[1], f\"{row['path']}.flac\"), \"rb\") as stream:\n",
    "                audio_bytes = stream.read()\n",
    "            # The second column is the transcript.\n",
    "            sink.write({\n",
    "                \"__key__\": row['path'],\n",
    "                \"audio.flac\": audio_bytes,\n",
    "                \"transcript.txt\": row['transcript']\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = output_dir + \"/train-{0000..0906}.tar\"\n",
    "dataset = (\n",
    "    wds.WebDataset(url)\n",
    "        .shuffle(100)\n",
    "        .decode(wds.torch_audio)\n",
    "        .to_tuple(\"transcript.txt\", \"audio.flac\")\n",
    ")\n",
    "dataloader = DataLoader(dataset.batched(4), batch_size=None)\n",
    "for transcripts, recordings in dataloader:\n",
    "    print(\"===========\")\n",
    "    print(transcripts)\n",
    "    print(recordings)\n",
    "    print(\"===========\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
